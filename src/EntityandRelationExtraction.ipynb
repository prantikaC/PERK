{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HZb40UpNv-h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "aS2EVohegOHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import ast\n",
        "from collections import defaultdict\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "-FMI0zvKf0mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os[\"OPENAI_API_KEY\"]=\" \"\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "hxlwde1OgDab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_FILE = \"PATRA_v1.txt\"\n",
        "OUTPUT_DIR = \"mailCsv\"\n",
        "FINAL_ENTITIES = \"entities.csv\"\n",
        "FINAL_RELATIONS = \"relations.csv\""
      ],
      "metadata": {
        "id": "njFPpQwBgJvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are an information extraction assistant.\n",
        "Extract entities and relations from emails following the ontology:\n",
        "\n",
        "Ontology classes (Neo4j node labels):\n",
        "Person, Email, Paper, Conference, Journal, Dataset, Method, Task, Metric, MailThread, Meeting, PaperStatus, SubmissionID.\n",
        "\n",
        "Object properties (Neo4j relationships):\n",
        "- sentBy (Email, Person/Journal/Conference)\n",
        "- receivedBy (Email, Person)\n",
        "- hasAuthor (Paper, Person)\n",
        "- identifies (SubmissionID, Paper)\n",
        "- inVenue (SubmissionID, Conference/Journal)\n",
        "- mentions (Email, Dataset/Method/Metric/Task)\n",
        "- notifies (Email, Meeting/SubmissionID)\n",
        "- partOf (Email, MailThread)\n",
        "- movesTo (PaperStatus/SubmissionID, PaperStatus)\n",
        "- usedFor (Dataset/Method, Task)\n",
        "- evaluates (Metric, Task/Method/Dataset)\n",
        "- uses(Method, Dataset)\n",
        "\n",
        "Data properties (Neo4j node attributes):\n",
        "- Person: personName, personEmail, affiliation\n",
        "- Paper: paperTitle\n",
        "- Conference: confTitle, confDate, confVenue\n",
        "- Journal: journalTitle\n",
        "- SubmissionID: identifier\n",
        "- PaperStatus: statusType, statusDate\n",
        "- Email: mailNum, mailDate, subject\n",
        "- MailThread: threadID, subject\n",
        "- Meeting: meetDate, meetTime, meetAgenda, meetLink\n",
        "- Dataset: datasetName\n",
        "- Method: methodName\n",
        "- Task: taskName\n",
        "- Metric: metricName\n",
        "\n",
        "Rules:\n",
        "- Every entity must have a stable ID (like p1, e1, s1 …), reusing the same ID for the same entity across emails (registry).\n",
        "- Output strictly two CSV blocks: Entities block first, then Relations block.\n",
        "- Entity CSV block headers: id,type,properties\n",
        "- Relation CSV block headers: start_id,end_id,relation\n",
        "- All properties must follow the ontology; no extra fields.\n",
        "- Output JSON-like strings inside the properties column.\n",
        "\n",
        "Few-shot examples:\n",
        "\n",
        "Example 1:\n",
        "Email text input:\n",
        "---\n",
        "Thread ID: EMNLP3456AB\n",
        "Mail ID: EMNLP3456ABH\n",
        "Date: 20-01-2025\n",
        "From: Dr. Michael Bradley (michael@cs.stanford.edu)\n",
        "To: Sunita Sen (scholar.sunita@iacs.res.in), Prof. Ramesh Bhatia (ramesh.bhatia@iacs.res.in), Dr. Ananya Chatterjee (ananya.chatterjee@ox.ac.uk)\n",
        "Subject: Discussion on Recent NLP Frameworks and Dataset Expansion Progress\n",
        "\n",
        "Dear Sunita, Prof. Bhatia, and Ananya,\n",
        "\n",
        "I hope you are all doing well. I wanted to provide some updates and continue our discussions on the advancements we are making with respect\n",
        "to our recent project submission to EMNLP 2024.\n",
        "\n",
        "**NLP Framework Integration:**\n",
        "\n",
        "Sunita, I received your report on the potential NLP frameworks that could be integrated into our study. The comparative analysis you provided between\n",
        "the traditional transformer models and the newer generative models was insightful.\n",
        "It seems like GPT-X models could add remarkable depth specifically for cultural nuance interpretation.\n",
        "\n",
        "- **Proposal:** I suggest that we test a subset of our dataset using these new models to examine their efficacy.\n",
        "This would involve coupling the NLP frameworks with demographic metadata, potentially uncovering new dimensions in cultural analysis.\n",
        "\n",
        "**Dataset Expansion Update:**\n",
        "\n",
        "1. **European and Asian Archives:**\n",
        "   - Ananya, your efforts in reaching out to archives have been phenomenal. I understand that the British Library and the National Archives of India have shown interest.\n",
        "   It's exciting to hear that preliminary talks regarding data access are in motion.\n",
        "\n",
        "2. **Stanford Resources:**\n",
        "   - I have identified several promising datasets within our Stanford Digital Repository that align with our research focus.\n",
        "   These include 'Early Modern Embassies' and 'Mediterranean Merchant Records'.\n",
        "    I am preparing a proposal to potentially collaborate with our Library Science Department for more streamlined data access.\n",
        "\n",
        "**Team Collaboration:**\n",
        "- **Recommendations:**\n",
        "  - We may need to set up a few technical workshops to ensure that our analytical strategies align with any new datasets and frameworks.\n",
        "  I propose February 5 as a date for the first session, pending everyone’s availability.\n",
        "\n",
        "Please share your thoughts on the above and let me know if there are specific areas you think we should delve deeper into.\n",
        "\n",
        "Thank you all for your dedication and the collaborative spirit you bring to this work. I look forward to our continued progress and the innovative insights that lie ahead.\n",
        "\n",
        "Warm regards,\n",
        "\n",
        "Michael Bradley\n",
        "Department of Computer Science\n",
        "Stanford University\n",
        "\n",
        "Output CSV:\n",
        "id,type,properties\n",
        "t1,MailThread,{\"threadID\": \"EMNLP3456AB\", \"subject\": \"Discussion on Recent NLP Frameworks and Dataset Expansion Progress\"}\n",
        "e1,Email,{\"mailNum\": \"EMNLP3456ABH\", \"mailDate\": \"2025-01-20T00:00:00\"}\n",
        "pn1,Person,{\"personName\": \"Michael Bradley\", \"personEmail\": \"michael@cs.stanford.edu\", \"affiliation\": \"Stanford University\"}\n",
        "pn2,Person,{\"personName\": \"Sunita Sen\", \"personEmail\": \"scholar.sunita@iacs.res.in\"}\n",
        "pn3,Person,{\"personName\": \"Ramesh Bhatia\", \"personEmail\": \"ramesh.bhatia@iacs.res.in\"}\n",
        "pn4,Person,{\"personName\": \"Ananya Chatterjee\", \"personEmail\": \"ananya.chatterjee@ox.ac.uk\"}\n",
        "tk1,Task,{\"taskName\": \"NLP Framework Comparative Analysis\"}\n",
        "me1,Method,{\"methodName\": \"GPT-X\"}\n",
        "d1,Dataset,{\"datasetName\": \"Early Modern Embassies\"}\n",
        "d2,Dataset,{\"datasetName\": \"Mediterranean Merchant Records\"}\n",
        "mg1,Meeting,{\"meetAgenda\": \"technical workshops to ensure that our analytical strategies align with any new datasets and frameworks\", \"meetDate\": \"2025-02-05\"}\n",
        "start_id,end_id,relation\n",
        "e1,pn1,sentBy\n",
        "e1,pn2,receivedBy\n",
        "e1,pn3,receivedBy\n",
        "e1,pn4,receivedBy\n",
        "e1,t1,partOf\n",
        "e1,tk1,mentions\n",
        "e1,me1,mentions\n",
        "e1,d1,mentions\n",
        "e1,d2,mentions\n",
        "me1,t1,usedFor\n",
        "d1,tk1,usedFor\n",
        "d2,tk1,usedFor\n",
        "e1,mg1,notifies\n",
        "\n",
        "Example 2:\n",
        "Email text input:\n",
        "---\n",
        "Thread ID: Y1L43Z\n",
        "Mail ID: YT6A33\n",
        "Date: 23-06-2019\n",
        "From: Sunita Sen (scholar.sunita@iacs.res.in)\n",
        "To: Prof. Ramesh Bhatia (ramesh.bhatia@iacs.res.in), Dr. Michael Bradley (michael@cs.stanford.edu), Dr. Ananya Chatterjee (ananya.chatterjee@ox.ac.uk)\n",
        "Subject: Confirmation of Meeting - Discussion on Revisions for ACM Journal Submission\n",
        "\n",
        "Dear Prof. Bhatia, Michael, and Ananya,\n",
        "\n",
        "Thank you all for quickly responding to the scheduling poll. Based on the feedback, I am pleased to confirm that our meeting on revising our paper\n",
        "for the ACM Journal will be held on June 26th, from 3 PM to 4:30 PM IST.\n",
        "\n",
        "Please join using the Zoom link below:\n",
        "\n",
        "Zoom Meeting Link: https://zoom.us/j/0987654321\n",
        "\n",
        "The agenda will include:\n",
        "- Reviewing the reviewers' comments in detail.\n",
        "- Discussing enhancements for a multimodal approach and refining feature extraction.\n",
        "- Establishing a clear plan for addressing the feedback and preparing the revised submission.\n",
        "\n",
        "Please be prepared with any data or insights you wish to bring to this meeting. It will be our chance to collaboratively ensure our submission meets the high standards required.\n",
        "\n",
        "Thank you, and I look forward to our continued collaboration.\n",
        "\n",
        "Warm regards,\n",
        "\n",
        "Sunita Sen\n",
        "Indian Association for the Cultivation of Science\n",
        "\n",
        "\n",
        "Output CSV:\n",
        "id,type,properties\n",
        "t2,MailThread,{\"threadID\": \"Y1L43Z\", \"subject\": \"Confirmation of Meeting - Discussion on Revisions for ACM Journal Submission\"}\n",
        "e2,Email,{\"mailNum\": \"YT6A33\", \"mailDate\": \"2019-06-23T00:00:00\"}\n",
        "pn1,Person,{\"personName\": \"Michael Bradley\", \"personEmail\": \"michael@cs.stanford.edu\", \"affiliation\": \"Stanford University\"}\n",
        "pn2,Person,{\"personName\": \"Sunita Sen\", \"personEmail\": \"scholar.sunita@iacs.res.in\", \"affiliation\": \"Indian Association for the Cultivation of Science\"}\n",
        "pn3,Person,{\"personName\": \"Ramesh Bhatia\", \"personEmail\": \"ramesh.bhatia@iacs.res.in\"}\n",
        "pn4,Person,{\"personName\": \"Ananya Chatterjee\", \"personEmail\": \"ananya.chatterjee@ox.ac.uk\"}\n",
        "mg2,Meeting,{\"meetDate\": \"2019-06-26\", \"meetTime\": \"15:00-16:30\", \"meetLink\": \"https://zoom.us/j/0987654321\", \"meetAgenda\": \"Reviewing the reviewers' comments in detail. Discussing enhancements for a multimodal approach and refining feature extraction. Establishing a clear plan for addressing the feedback and preparing the revised submission.\"}\n",
        "start_id,end_id,relation\n",
        "e2,pn2,sentBy\n",
        "e2,pn1,receivedBy\n",
        "e2,pn3,receivedBy\n",
        "e2,pn4,receivedBy\n",
        "e2,t2,partOf\n",
        "e2,mg2,notifies\n",
        "\n",
        "\n",
        "Example 3:\n",
        "Email text input:\n",
        "---\n",
        "Thread ID: 9K07LI\n",
        "Mail ID: YT6A35\n",
        "Date: 10-08-2019\n",
        "From: ACM Journal on Computing and Cultural Heritage (do-not-reply@acm-jocch.org)\n",
        "To: Sunita Sen (scholar.sunita@iacs.res.in)\n",
        "Subject: Acknowledgement of Submission - Paper ID: JOCCH21-TSA039\n",
        "\n",
        "Dear Ms. Sunita Sen,\n",
        "\n",
        "We are pleased to inform you that your paper:\n",
        "Title: \"Temporal Sentiment Analysis in Historical Archives\"\n",
        "Author: Sunita Sen, Ramesh Bhatia, Ananya Chatterjee, Michael Bradley\n",
        "\n",
        "has been successfully submitted to the ACM Journal on Computing and Cultural Heritage. Your submission has been assigned the ID JOCCH21-TSA039.\n",
        "\n",
        "The peer review process will commence shortly, and you will be notified once a decision has been made. If you have any questions, please do not hesitate to contact us at support@acm-jocch.org.\n",
        "\n",
        "Thank you for your submission.\n",
        "\n",
        "Best regards,\n",
        "\n",
        "Editorial Office\n",
        "ACM Journal on Computing and Cultural Heritage\n",
        "\n",
        "Output CSV:\n",
        "id,type,properties\n",
        "t3,MailThread,{\"threadID\": \"9K07LI\", \"subject\": \"Acknowledgement of Submission - Paper ID: JOCCH21-TSA039\"}\n",
        "e3,Email,{\"mailNum\": \"YT6A35\", \"mailDate\": \"2019-08-10T00:00:00\"}\n",
        "pn1,Person,{\"personName\": \"Michael Bradley\", \"personEmail\": \"michael@cs.stanford.edu\", \"affiliation\": \"Stanford University\"}\n",
        "pn2,Person,{\"personName\": \"Sunita Sen\", \"personEmail\": \"scholar.sunita@iacs.res.in\", \"affiliation\": \"Indian Association for the Cultivation of Science\"}\n",
        "pn3,Person,{\"personName\": \"Ramesh Bhatia\", \"personEmail\": \"ramesh.bhatia@iacs.res.in\"}\n",
        "pn4,Person,{\"personName\": \"Ananya Chatterjee\", \"personEmail\": \"ananya.chatterjee@cs.stanford.edu\"}\n",
        "j1,Journal,{\"journalTitle\": \"ACM Journal on Computing and Cultural Heritage\"}\n",
        "pa1,Paper,{\"paperTitle\": \"Temporal Sentiment Analysis in Historical Archives\"}\n",
        "tk2,Task,{\"taskName\": \"Temporal Sentiment Analysis\"}\n",
        "d3,Dataset,{\"datasetName\": \"Historical Archives\"}\n",
        "s1,SubmissionID,{\"identifier\": \"JOCCH21-TSA039\"}\n",
        "ps1,PaperStatus,{\"statusType\": \"Submitted\", \"statusDate\": \"2019-08-10\"}\n",
        "start_id,end_id,relation\n",
        "e3,j1,sentBy\n",
        "e3,pn2,receivedBy\n",
        "e3,t3,partOf\n",
        "pa1,p1,hasAuthor\n",
        "pa1,p2,hasAuthor\n",
        "pa1,p3,hasAuthor\n",
        "pa1,p4,hasAuthor\n",
        "e3,tk2,mentions\n",
        "e3,d3,mentions\n",
        "d3,tk2,usedFor\n",
        "s1,pa1,identifies\n",
        "s1,ps1,movesTo\n",
        "s1,j1,inVenue\n",
        "e3,s1,notifies\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MNbc_L3vgtH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information Extraction and Parsing"
      ],
      "metadata": {
        "id": "K9YCBy1Dhe3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_llm(email_text):\n",
        "    \"\"\"Call LLM with system prompt + email text and return raw output\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": email_text},\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "8bRSUG22hUiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_llm_output(output_text):\n",
        "    \"\"\"Return (entities_rows, relations_rows)\"\"\"\n",
        "    blocks = output_text.strip().split(\"\\n\\n\")\n",
        "    entities, relations = [], []\n",
        "\n",
        "    for block in blocks:\n",
        "        lines = [l.strip() for l in block.splitlines() if l.strip()]\n",
        "        if not lines:\n",
        "            continue\n",
        "        header = lines[0].lower()\n",
        "        rows = lines[1:]\n",
        "        if header.startswith(\"id,type,properties\"):\n",
        "            for r in rows:\n",
        "                parts = r.split(\",\", 2)\n",
        "                if len(parts) == 3:\n",
        "                    entities.append(parts)\n",
        "        elif header.startswith(\"start_id,end_id,relation\"):\n",
        "            for r in rows:\n",
        "                parts = r.split(\",\")\n",
        "                if len(parts) == 3:\n",
        "                    relations.append(parts)\n",
        "    return entities, relations"
      ],
      "metadata": {
        "id": "Dlc0S6a-hozp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv(path, headers, rows):\n",
        "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(headers)\n",
        "        writer.writerows(rows)"
      ],
      "metadata": {
        "id": "Og1SVkDGhv7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Registry formation to prevent duplication"
      ],
      "metadata": {
        "id": "dCmrvaF4hwn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entity_registry = {}             # stable_id -> {\"type\": ..., \"properties\": {...}}\n",
        "entity_index = defaultdict(dict) # class_type -> unique_key -> stable_id\n",
        "relations_all = []"
      ],
      "metadata": {
        "id": "XtPWOrB5hz9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_key(etype, props):\n",
        "    if etype == \"Person\":\n",
        "        return props.get(\"personEmail\")\n",
        "    elif etype == \"Paper\":\n",
        "        return props.get(\"paperTitle\")\n",
        "    elif etype == \"Conference\":\n",
        "        return props.get(\"confTitle\")\n",
        "    elif etype == \"Journal\":\n",
        "        return props.get(\"journalTitle\")\n",
        "    elif etype == \"Dataset\":\n",
        "        return props.get(\"datasetName\")\n",
        "    elif etype == \"Method\":\n",
        "        return props.get(\"methodName\")\n",
        "    elif etype == \"Task\":\n",
        "        return props.get(\"taskName\")\n",
        "    elif etype == \"Metric\":\n",
        "        return props.get(\"metricName\")\n",
        "    elif etype == \"SubmissionID\":\n",
        "        return props.get(\"identifier\")\n",
        "    elif etype == \"PaperStatus\":\n",
        "        return f\"{props.get('statusType','')}|{props.get('statusDate','')}\"\n",
        "    elif etype == \"Email\":\n",
        "        return props.get(\"mailNum\")\n",
        "    elif etype == \"MailThread\":\n",
        "        return props.get(\"threadID\")\n",
        "    elif etype == \"Meeting\":\n",
        "        return f\"{props.get('meetDate','')}|{props.get('meetTime','')}|{props.get('meetAgenda','')}\"\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "L7hwFRWJh7xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_entity(etype, props):\n",
        "    key = get_unique_key(etype, props)\n",
        "    if key:\n",
        "        if key in entity_index[etype]:\n",
        "            stable_id = entity_index[etype][key]\n",
        "            for k, v in props.items():\n",
        "                if k not in entity_registry[stable_id][\"properties\"]:\n",
        "                    entity_registry[stable_id][\"properties\"][k] = v\n",
        "            return stable_id\n",
        "        else:\n",
        "            stable_id = f\"{etype[0].lower()}{len(entity_registry)+1}\"\n",
        "            entity_registry[stable_id] = {\"type\": etype, \"properties\": props.copy()}\n",
        "            entity_index[etype][key] = stable_id\n",
        "            return stable_id\n",
        "    else:\n",
        "        stable_id = f\"{etype[0].lower()}{len(entity_registry)+1}\"\n",
        "        entity_registry[stable_id] = {\"type\": etype, \"properties\": props.copy()}\n",
        "        return stable_id"
      ],
      "metadata": {
        "id": "wibvw6GQiJPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_email(email_text, email_num):\n",
        "    print(f\"Processing email {email_num}...\")\n",
        "    llm_output = call_llm(email_text)\n",
        "    entities_raw, relations_raw = parse_llm_output(llm_output)\n",
        "\n",
        "    temp_to_global = {}\n",
        "    entities_rows = []\n",
        "\n",
        "    # Parse properties correctly and merge into global registry\n",
        "    for eid, etype, props_str in entities_raw:\n",
        "        props = parse_props(props_str)\n",
        "        stable_id = merge_entity(etype, props)\n",
        "        temp_to_global[eid] = stable_id\n",
        "        entities_rows.append([stable_id, etype, props])\n",
        "\n",
        "    # Map relations to stable IDs\n",
        "    relations_rows = []\n",
        "    for start_id, end_id, rel in relations_raw:\n",
        "        start_global = temp_to_global.get(start_id, start_id)\n",
        "        end_global = temp_to_global.get(end_id, end_id)\n",
        "        relations_rows.append([start_global, end_global, rel])\n",
        "        relations_all.append([start_global, end_global, rel])\n",
        "\n",
        "    # Write per-email CSVs\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    write_csv(os.path.join(OUTPUT_DIR, f\"entities_email{email_num}.csv\"),\n",
        "              [\"id\",\"type\",\"properties\"], entities_rows)\n",
        "    write_csv(os.path.join(OUTPUT_DIR, f\"relations_email{email_num}.csv\"),\n",
        "              [\"start_id\",\"end_id\",\"relation\"], relations_rows)"
      ],
      "metadata": {
        "id": "U2KWxIOoiJ4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ef main():\n",
        "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "        emails = [e.strip() for e in f.read().split(\"**EMAIL_END**\") if e.strip()]\n",
        "\n",
        "    for i, email_text in enumerate(emails, start=1):\n",
        "        process_email(email_text, i)\n",
        "\n",
        "    # Final merged CSVs\n",
        "    entity_rows = [(eid, data[\"type\"], data[\"properties\"]) for eid, data in entity_registry.items()]\n",
        "    write_csv(FINAL_ENTITIES, [\"id\",\"type\",\"properties\"], entity_rows)\n",
        "    write_csv(FINAL_RELATIONS, [\"start_id\",\"end_id\",\"relation\"], relations_all)\n",
        "\n",
        "    print(f\"✅ Done! Final entities: {FINAL_ENTITIES}, relations: {FINAL_RELATIONS}\")"
      ],
      "metadata": {
        "id": "u0w7j4HpiPmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "DpOo6KeyiS0I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}